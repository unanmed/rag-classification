# 搭配 LangBotPluginDocument 的文本分类插件

该项目是 [LangBot](https://github.com/RockChinQ/LangBot) 插件 [LangBotPluginDocument](https://github.com/unanmed/LangBotPluginDocument) 的拓展功能，允许你自定义训练出一个适用于其中的文本分类模型，更精确地判断出用户提问是更偏向于代码，还是更偏向于文本，以及是否需要参考文档，从而提高文档检索准确度，精准判断是否需要参考文档，降低运行成本。

## 准备训练集

打开 `datasets.json`，你可以看到其中分为了两个属性，`text` 和 `label`，其中 `text` 表示输入给模型训练的文本，`label` 对应项表示这个文本分类 `[是否偏向于代码, 是否需要参考文档]`，其中第一项填 1 表示偏向于代码，填 0 表示偏向于文本，第二项填 1 表示需要参考文档，填 0 表示不需要参考文档。可以参考示例提供数据集。如果 `json` 格式不方便，可以自行使用 `csv` 等格式的文件，然后转换为 `json` 后用于训练。可以参考示例训练集填写。

## 开始训练

安装 `requirements.txt` 文件中的依赖，如果你使用 `nvidia` 显卡，可以安装 `cuda` 版 `pytorch`，加快训练速度。安装完毕后，直接运行 `python tarin.py` 即可开始训练。

默认使用 `google-bert/bert-base-chinese` 作为预训练模型，如果需要其他模型，可以在 `config.json` 中修改配置。配置说明：

-   `model`: 使用的预训练模型。
-   `output`: 模型的输出路径。
-   `epoches`: 训练轮数，越大效果越好，但是训练时长也会变长，如果语境不复杂，而且训练集数量多，建议设置在 10 以内。如果训练集数量少，可以设大一点，但是需要注意可能会过拟合。
-   `batch_size`: 每次训练时处理的数据量，调大点有助于防止过拟合，以及减少震荡的发生，但是会占用更多的显存。
-   `learning_rate`: 初始学习率，学习率过高时可能会导致损失值震荡，但是也会加快模型训练速度，学习率较低时会使模型跳出局部最优，在小损失值的情况下继续降低损失值。训练过程中会动态调整学习率。

## 插入 LangBotPluginDocument 插件

训练完毕后，训练出来的模型会生成在 `model` 文件夹中，将除 `checkpoint` 开头的文件夹外的内容全部复制到文档插件中的对应文件夹下，然后在文档插件的 `config.json` 中填写相应配置即可。
